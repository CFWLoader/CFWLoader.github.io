---
title: 机器学习作业练习(四)
date: 2018-05-06 19:59:07
tags:
    - 机器学习
    - 作业练习
    - 多层感知机
    - R
categories:	机器学习
---

## 题目4.1 - 线性搜索

考察一般梯度下降用的更新公式：

$$
w_{t+1} = w_t - \eta_t d_t
$$

第一问是用`2阶泰勒`对任意$E^T(w_{t+1})$在$w_t$的近似展开。

{% post_link "数学方法技巧整理" "泰勒展开定义式" %}

于是根据定义式有：

$$
\begin{align}
E^T(w_{t+1}) & = E^T(w_t) + \sum_{i=1}^{N} (w_{t+1,i} - w_{t,i}) \frac{\partial E^T}{\partial w_{t, i}} + \sum_{i=1}^{N} \sum_{j=1}^{N} (w_{t+1,i} - w_{t,i})(w_{t+1,j} - w_{t,j}) \frac{\partial E^T}{\partial w_{t, i} \partial w_{t,j}} \\
& = E^T(w_t) + \sum_{i=1}^{N} (-\eta_t d_{t,i}) \frac{\partial E^T}{\partial w_{t, i}} + \sum_{i=1}^{N} \sum_{j=1}^{N} (-\eta_t d_{t,i})(-\eta_t d_{t,j}) \frac{\partial E^T}{\partial w_{t, i} \partial w_{t,j}} \\
& = E^T(w_t) - \eta_t d_t \nabla E^T(w_t) + \eta_t^2 d_t^T \mathbf{H} E^T(w_t) d_t
\end{align}
$$

第二问是利用上述推导式以及不等式$E^T(w_{t+1}) \leq E^T(w_t)$推导步长$\eta_t$的上下界。

$$
\begin{align}
E^T(w_{t+1}) & \leq E^T(w_t) \\
E^T(w_t) - \eta_t d_t \nabla E^T(w_t) + \eta_t^2 d_t^T \mathbf{H} E^T(w_t) d_t & \leq E^T(w_t) \\
- \eta_t d_t \nabla E^T(w_t) + \eta_t^2 d_t^T \mathbf{H} E^T(w_t) d_t & \leq 0 \\
\eta_t^2 d_t^T \mathbf{H} E^T(w_t) d_t & \leq \eta_t d_t \nabla E^T(w_t)
\end{align}
$$

不等式至此需要分情况讨论了。

当$d_t^T \mathbf{H} E^T(w_t) d_t > 0, d_t \nabla E^T(w_t) < 0$时，有且仅有$\eta_t=0$；

令符号$H=d_t^T \mathbf{H} E^T(w_t) d_t, E=d_t \nabla E^T(w_t)$，则有：

当$H,E<0$或$H,E>0$时，$\eta_t \leq \frac{E}{H}$；

当$H<0,E>0$时，$\eta_t$为大于零任意值。

第三问通过$$E^T(w_t)=\frac{1}{2}(w-w^*)^T\mathbf{H}(w-w^*)$$求解当前权值下最优步长$\eta_t^*$。