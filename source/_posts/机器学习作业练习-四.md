---
title: 机器学习作业练习(四)
date: 2018-05-06 19:59:07
tags:
    - 机器学习
    - 作业练习
    - 多层感知机
    - R
categories:	机器学习
---

## 题目4.1 - 线性搜索

考察一般梯度下降用的更新公式：

$$
w_{t+1} = w_t - \eta_t d_t
$$

第一问是用`2阶泰勒`对任意$E^T(w_{t+1})$在$w_t$的近似展开。

{% post_link "数学方法技巧整理" "泰勒展开定义式" %}

于是根据定义式有：

$$
\begin{align}
E^T(w_{t+1}) & = E^T(w_t) + \sum_{i=1}^{N} (w_{t+1,i} - w_{t,i}) \frac{\partial E^T}{\partial w_{t, i}} + \sum_{i=1}^{N} \sum_{j=1}^{N} (w_{t+1,i} - w_{t,i})(w_{t+1,j} - w_{t,j}) \frac{\partial E^T}{\partial w_{t, i} \partial w_{t,j}} \\
& = E^T(w_t) + \sum_{i=1}^{N} (-\eta_t d_{t,i}) \frac{\partial E^T}{\partial w_{t, i}} + \sum_{i=1}^{N} \sum_{j=1}^{N} (-\eta_t d_{t,i})(-\eta_t d_{t,j}) \frac{\partial E^T}{\partial w_{t, i} \partial w_{t,j}} \\
& = E^T(w_t) - \eta_t d_t \nabla E^T(w_t) + \eta_t^2 d_t^T \mathbf{H} E^T(w_t) d_t
\end{align}
$$

第二问是利用上述推导式以及不等式$E^T(w_{t+1}) \leq E^T(w_t)$推导步长$\eta_t$的上下界。

$$
\begin{align}
E^T(w_{t+1}) & \leq E^T(w_t) \\
E^T(w_t) - \eta_t d_t \nabla E^T(w_t) + \eta_t^2 d_t^T \mathbf{H} E^T(w_t) d_t & \leq E^T(w_t) \\
- \eta_t d_t \nabla E^T(w_t) + \eta_t^2 d_t^T \mathbf{H} E^T(w_t) d_t & \leq 0 \\
\eta_t^2 d_t^T \mathbf{H} E^T(w_t) d_t & \leq \eta_t d_t \nabla E^T(w_t)
\end{align}
$$

不等式至此需要分情况讨论了。

当$d_t^T \mathbf{H} E^T(w_t) d_t > 0, d_t \nabla E^T(w_t) < 0$时，有且仅有$\eta_t=0$；

令符号$H=d_t^T \mathbf{H} E^T(w_t) d_t, E=d_t \nabla E^T(w_t)$，则有：

当$H,E<0$或$H,E>0$时，$\eta_t \leq \frac{E}{H}$；

当$H<0,E>0$时，$\eta_t$为大于零任意值。

第三问通过$$E^T(w_t)=\frac{1}{2}(w-w^*)^T\mathbf{H}(w-w^*)$$求解当前权值下最优步长$\eta_t^*$。

首先查看二阶泰勒展开式：

$$
E^T(w_{t+1}) = E^T(w_t) - \eta_t d_t \nabla E^T(w_t) + \eta_t^2 d_t^T \mathbf{H} E^T(w_t) d_t
$$

根据链式法则有：

$$
\frac{\partial E^T(w_{t+1})}{\partial \eta_t} = \frac{\partial E^T(w_{t+1})}{\partial w_{t+1}}\frac{\partial w_{t+1}}{\partial \eta_t}
$$

而：

$$
w_{t+1} = w_{t} - \eta_t d_t
$$

可得：

$$
\frac{\partial w_{t+1}}{\partial \eta_t} = - d_t
$$

另外：

$$
\begin{align}
\frac{\partial E^T(w_{t+1})}{\partial w_{t+1}} & = \frac{\partial[\frac{1}{2}(w_t-w^*)^T\mathbf{H}(w_t-w^*) - \eta_t d_t \nabla E^T(w_t) + \eta_t^2 d_t^T \mathbf{H} E^T(w_t) d_t]}{\partial w_{t+1}} \\
& = \frac{1}{2}\mathbf{H}(w_t-w^*) - \eta_t d_t^T \mathbf{H} E^T(w_t) d_t
\end{align}
$$

所以：

$$
\frac{\partial E^T(w_{t+1})}{\partial \eta_t} = [\frac{1}{2}\mathbf{H}(w_t-w^*) - \eta_t d_t^T \mathbf{H} E^T(w_t) d_t](- d_t)
$$

令算式等于0即可解得$\eta_t^*$的表达式。

最后一问是证步长$\eta_t$与搜索方向$d_t$正交，这题笔者真不会证了。

## 题目4.2 - 下降方法比较

该题比较三种下降法：

1. 学习率为常数的最速下降法
2. 线性搜索学习率的最速下降法
3. 共轭梯度法