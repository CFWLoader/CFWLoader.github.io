---
title: 机器学习作业练习(四)
date: 2018-05-06 19:59:07
tags:
    - 机器学习
    - 作业练习
    - 多层感知机
    - R
categories:	机器学习
---

## 题目4.1 - 线性搜索

考察一般梯度下降用的更新公式：

$$
w_{t+1} = w_t - \eta_t d_t
$$

第一问是用`2阶泰勒`对任意$E^T(w_{t+1})$在$w_t$的近似展开。

{% post_link "数学方法技巧整理" "泰勒展开定义式" %}

于是根据定义式有：

$$
\begin{align}
E^T(w_{t+1}) & = E^T(w_t) + \sum_{i=1}^{N} (w_{t+1,i} - w_{t,i}) \frac{\partial E^T}{\partial w_{t, i}} + \sum_{i=1}^{N} \sum_{j=1}^{N} (w_{t+1,i} - w_{t,i})(w_{t+1,j} - w_{t,j}) \frac{\partial E^T}{\partial w_{t, i} \partial w_{t,j}} \\
& = E^T(w_t) + \sum_{i=1}^{N} (-\eta_t d_{t,i}) \frac{\partial E^T}{\partial w_{t, i}} + \sum_{i=1}^{N} \sum_{j=1}^{N} (-\eta_t d_{t,i})(-\eta_t d_{t,j}) \frac{\partial E^T}{\partial w_{t, i} \partial w_{t,j}} \\
& = E^T(w_t) - \eta_t d_t \nabla E^T(w_t) + \eta_t^2 d_t^T \mathbf{H} E^T(w_t) d_t
\end{align}
$$

第二问是利用上述推导式推导步长$\eta_t$的上下界。